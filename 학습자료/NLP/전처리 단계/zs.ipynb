{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Json 등 형식에 맞는 파일 불러오기\\n2. article text를 추출\\n3. stop word 적용\\n4. text rank 핵심 문장으로 요약\\n5. //konply에서 명사만 추출 ex) okt.nouns(string)\\n6. 키워드 추출 (ex: TF-IDF)\\n7. 아니면 핵심 문장간 유사도 비교\\n8. 합당한 문장에서 지명 대조\\n9. 추출한 지명 따로 저장\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Json 등 형식에 맞는 파일 불러오기\n",
    "2. article text를 추출\n",
    "3. stop word 적용\n",
    "4. text rank 핵심 문장으로 요약\n",
    "5. //konply에서 명사만 추출 ex) okt.nouns(string)\n",
    "6. 키워드 추출 (ex: TF-IDF)\n",
    "7. 아니면 핵심 문장간 유사도 비교\n",
    "8. 합당한 문장에서 지명 대조\n",
    "9. 추출한 지명 따로 저장\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "년도를 입력하세요. ex) 2019 2019\n",
      "시작 월을 입력하세요. ex) 03 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201911article.csv\n",
      "데이터 개수 : (742, 4)\n",
      "742\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>popular</th>\n",
       "      <th>subject</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20191102</td>\n",
       "      <td>society</td>\n",
       "      <td>단독한국당 신보라 의원 비서 남편 영입 자격 논란</td>\n",
       "      <td>자유한국당 신보라 의원왼쪽과 황교안 대표. 동아일보       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20191102</td>\n",
       "      <td>society</td>\n",
       "      <td>몽골서 5000만원에 사온 소똥구리 200마리.. 말똥 구해 먹이며 애지중지</td>\n",
       "      <td>지난 29일 경북 영양에 있는 국립생태원 멸종위기종복원센터에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20191102</td>\n",
       "      <td>society</td>\n",
       "      <td>이언주 과거사고 나발이고 미국·일본에 도움 청해야</td>\n",
       "      <td>무소속 이언주 국회의원이 2일 충북 청주시 상당공원 인근 도로에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20191102</td>\n",
       "      <td>society</td>\n",
       "      <td>농민 호주머니 노린다..천안 북부 농촌 다방 티켓영업 성행</td>\n",
       "      <td>여기 저기 티켓다방 천안연합뉴스 이은중 기자  충남 천안시 성환...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20191102</td>\n",
       "      <td>society</td>\n",
       "      <td>45년 전 전통신앙인 줄 알고 세운 비석 알고보니 일제 잔재</td>\n",
       "      <td>지난달 31일 청주시 서원구 사직동 충혼탑 입구에 설치된 천지신...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>20191130</td>\n",
       "      <td>society</td>\n",
       "      <td>박찬주 전 대장 외교·안보 고립무원..무장해제 됐다</td>\n",
       "      <td>아산뉴시스이종익 기자  박찬주 전 육군대장이 30일 오후 이건영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>20191130</td>\n",
       "      <td>society</td>\n",
       "      <td>금연약 먹고 자살충동..모르는 게 약</td>\n",
       "      <td>뉴스데스크 ◀ 앵커 ▶이제 내일이면 12월입니다.연초에 금연 다짐하셨던 분들 많이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>739</td>\n",
       "      <td>20191130</td>\n",
       "      <td>society</td>\n",
       "      <td>숨진 기수 유서 통해 조교사 채용 비리 폭로..한국마사회 사실 무근</td>\n",
       "      <td>한국마사회가 운영하는 경마장 렛츠런파크 부산·경남에서 2년 사이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>20191130</td>\n",
       "      <td>society</td>\n",
       "      <td>테러범에 달려든 런던 시민들..존슨 대단한 용기 칭찬</td>\n",
       "      <td>런던 브리지 테러 용의자를 둘러싼 경찰 연합뉴스         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>20191130</td>\n",
       "      <td>society</td>\n",
       "      <td>경남서 첫 퀴어축제 개최..반대 종교단체 맞불 집회도</td>\n",
       "      <td>경남퀴어문화축제 즐기는 사람들 창원연합뉴스 한지은 기자  30일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  popular                                     subject  \\\n",
       "0    20191102  society                 단독한국당 신보라 의원 비서 남편 영입 자격 논란   \n",
       "1    20191102  society  몽골서 5000만원에 사온 소똥구리 200마리.. 말똥 구해 먹이며 애지중지   \n",
       "2    20191102  society                 이언주 과거사고 나발이고 미국·일본에 도움 청해야   \n",
       "3    20191102  society            농민 호주머니 노린다..천안 북부 농촌 다방 티켓영업 성행   \n",
       "4    20191102  society           45년 전 전통신앙인 줄 알고 세운 비석 알고보니 일제 잔재   \n",
       "..        ...      ...                                         ...   \n",
       "737  20191130  society                박찬주 전 대장 외교·안보 고립무원..무장해제 됐다   \n",
       "738  20191130  society                        금연약 먹고 자살충동..모르는 게 약   \n",
       "739  20191130  society       숨진 기수 유서 통해 조교사 채용 비리 폭로..한국마사회 사실 무근   \n",
       "740  20191130  society               테러범에 달려든 런던 시민들..존슨 대단한 용기 칭찬   \n",
       "741  20191130  society               경남서 첫 퀴어축제 개최..반대 종교단체 맞불 집회도   \n",
       "\n",
       "                                               article  \n",
       "0               자유한국당 신보라 의원왼쪽과 황교안 대표. 동아일보       ...  \n",
       "1               지난 29일 경북 영양에 있는 국립생태원 멸종위기종복원센터에서 ...  \n",
       "2               무소속 이언주 국회의원이 2일 충북 청주시 상당공원 인근 도로에...  \n",
       "3               여기 저기 티켓다방 천안연합뉴스 이은중 기자  충남 천안시 성환...  \n",
       "4               지난달 31일 청주시 서원구 사직동 충혼탑 입구에 설치된 천지신...  \n",
       "..                                                 ...  \n",
       "737             아산뉴시스이종익 기자  박찬주 전 육군대장이 30일 오후 이건영...  \n",
       "738  뉴스데스크 ◀ 앵커 ▶이제 내일이면 12월입니다.연초에 금연 다짐하셨던 분들 많이 ...  \n",
       "739             한국마사회가 운영하는 경마장 렛츠런파크 부산·경남에서 2년 사이...  \n",
       "740             런던 브리지 테러 용의자를 둘러싼 경찰 연합뉴스         ...  \n",
       "741             경남퀴어문화축제 즐기는 사람들 창원연합뉴스 한지은 기자  30일...  \n",
       "\n",
       "[742 rows x 4 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy = input('년도를 입력하세요. ex) 2019')\n",
    "mmm = input('시작 월을 입력하세요. ex) 03')\n",
    "#mmm_e = input('종료 월을 입력하세요. ex) 03')\n",
    "\n",
    "filename_ = str(yyy)+str(mmm)+'article.csv'\n",
    "print(filename_)\n",
    "\n",
    "# 1. csv file 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "try :  \n",
    "    csv_data = pd.read_csv(filename_, delimiter=',', encoding='UTF-8')\n",
    "except:\n",
    "    print(filename_+' 열기 실패')\n",
    "    exit(1)\n",
    "\n",
    "# 행렬 개수 확인\n",
    "print(\"데이터 개수 :\",csv_data.shape)\n",
    "print(csv_data.shape[0])\n",
    "print()\n",
    "\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['양구군', '화천군', '삼척시', '홍천군', '정선군', '원주시', '춘천시', '횡성군', '고성군', '철원군', '태백시', '속초시', '평창군', '인제군', '양양군', '동해시', '강릉시', '영월군']\n"
     ]
    }
   ],
   "source": [
    "# 강원도 지명 리스트 준비\n",
    "KW=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\강원도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        KW.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "KW = KW[0].split(' ')\n",
    "KW.remove('')\n",
    "print(KW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['수원시', '영통구', '수원시', '장안구', '광명시', '고양시', '덕양구', '안산시', '단원구', '성남시', '수정구', '군포시', '평택시', '안양시', '동안구', '포천시', '안양시', '만안구', '부천시', '고양시', '일산서구', '오산시', '안성시', '수원시', '팔달구', '성남시', '중원구', '성남시', '분당구', '안산시', '상록구', '양주시', '연천군', '파주시', '수원시', '권선구', '의왕시', '이천시', '의정부시', '고양시', '일산동구', '용인시', '처인구', '여주시', '과천시', '광주시', '동두천시', '하남시', '가평군', '용인시', '기흥구', '화성시', '양평군', '용인시', '수지구', '시흥시', '남양주시', '구리시', '김포시']\n"
     ]
    }
   ],
   "source": [
    "# 경기도 지명 리스트 준비\n",
    "GGD=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\경기도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        GGD.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "GGD = GGD[0].split(' ')\n",
    "GGD.remove('')\n",
    "print(GGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['함양군', '고성군', '사천시', '양산시', '합천군', '산청군', '거제시', '창원시', '마산회원구', '통영시', '거창군', '창원시', '성산구', '김해시', '창녕군', '밀양시', '하동군', '의령군', '함안군', '창원시', '진해구', '창원시', '마산합포구', '남해군', '진주시', '창원시', '의창구']\n"
     ]
    }
   ],
   "source": [
    "# 경상남도 지명 리스트 준비\n",
    "GSND=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\경상남도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        GSND.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "GSND = GSND[0].split(' ')\n",
    "GSND.remove('')\n",
    "print(GSND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['구미시', '고령군', '포항시', '북구', '성주군', '영덕군', '포항시', '남구', '문경시', '경산시', '울진군', '김천시', '봉화군', '청송군', '칠곡군', '울릉군', '영양군', '안동시', '군위군', '의성군', '예천군', '상주시', '영주시', '경주시', '영천시', '청도군']\n"
     ]
    }
   ],
   "source": [
    "# 경상북도 지명 리스트 준비\n",
    "GSBD=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\경상북도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        GSBD.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "GSBD = GSBD[0].split(' ')\n",
    "GSBD.remove('')\n",
    "print(GSBD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남구', '광산구', '동구', '북구', '서구']\n"
     ]
    }
   ],
   "source": [
    "# 광주광역시 지명 리스트 준비\n",
    "GJ=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\광주광역시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        GJ.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "GJ = GJ[0].split(' ')\n",
    "GJ.remove('')\n",
    "print(GJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남구', '달성군', '달서구', '동구', '수성구', '북구', '중구', '서구']\n"
     ]
    }
   ],
   "source": [
    "# 대구광역시 지명 리스트 준비\n",
    "DG=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\대구광역시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        DG.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "DG = DG[0].split(' ')\n",
    "DG.remove('')\n",
    "print(DG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['동구', '대덕구', '유성구', '중구', '서구']\n"
     ]
    }
   ],
   "source": [
    "# 대전광역시 지명 리스트 준비\n",
    "DJ=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\대전광역시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        DJ.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "DJ = DJ[0].split(' ')\n",
    "DJ.remove('')\n",
    "print(DJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남구', '사하구', '사상구', '동구', '금정구', '부산진구', '강서구', '연제구', '해운대구', '중구', '북구', '수영구', '영도구', '동래구', '기장군', '서구']\n"
     ]
    }
   ],
   "source": [
    "# 부산광역시 지명 리스트 준비\n",
    "BS=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\부산광역시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        BS.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "BS = BS[0].split(' ')\n",
    "BS.remove('')\n",
    "print(BS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['금천구', '송파구', '노원구', '중랑구', '동작구', '관악구', '서대문구', '양천구', '성북구', '강남구', '마포구', '강서구', '서초구', '구로구', '영등포구', '성동구', '하남시', '용산구', '종로구', '강동구', '동대문구', '강북구', '광진구', '도봉구', '중구', '은평구']\n"
     ]
    }
   ],
   "source": [
    "# 서울특별시 지명 리스트 준비\n",
    "SO=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\서울특별시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        SO.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "SO = SO[0].split(' ')\n",
    "SO.remove('')\n",
    "print(SO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['세종시']\n"
     ]
    }
   ],
   "source": [
    "# 세종특별자치시 지명 리스트 준비\n",
    "SJ=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\세종특별자치시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        SJ.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "SJ = SJ[0].split(' ')\n",
    "SJ.remove('')\n",
    "print(SJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남구', '동구', '북구', '중구', '울주군']\n"
     ]
    }
   ],
   "source": [
    "# 울산광역시 지명 리스트 준비\n",
    "US=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\울산광역시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        US.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "US = US[0].split(' ')\n",
    "US.remove('')\n",
    "print(US)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['옹진군', '동구', '연수구', '미추홀구', '강화군', '남동구', '중구', '계양구', '서구', '부평구']\n"
     ]
    }
   ],
   "source": [
    "# 인천광역시 지명 리스트 준비\n",
    "IC=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\인천광역시list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        IC.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "IC = IC[0].split(' ')\n",
    "IC.remove('')\n",
    "print(IC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고흥군', '장흥군', '구례군', '광양시', '보성군', '해남군', '완도군', '진도군', '무안군', '순천시', '영광군', '나주시', '장성군', '곡성군', '담양군', '목포시', '영암군', '강진군', '화순군', '신안군', '여수시', '함평군']\n"
     ]
    }
   ],
   "source": [
    "# 전라남도지명 리스트 준비\n",
    "JND=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\전라남도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        JND.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "JND = JND[0].split(' ')\n",
    "JND.remove('')\n",
    "print(JND)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['장수군', '임실군', '김제시', '전주시', '덕진구', '전주시', '완산구', '익산시', '부안군', '정읍시', '진안군', '완주군', '무주군', '고창군', '순창군', '군산시', '남원시']\n"
     ]
    }
   ],
   "source": [
    "# 전라북도지명 리스트 준비\n",
    "JBD=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\전라북도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        JBD.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "JBD = JBD[0].split(' ')\n",
    "JBD.remove('')\n",
    "print(JBD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['보은군', '증평군', '영동군', '청주시', '상당구', '단양군', '청주시', '서원구', '충주시', '제천시', '진천군', '괴산군', '음성군', '청주시', '청원구', '청주시', '흥덕구', '옥천군']\n"
     ]
    }
   ],
   "source": [
    "# 충청북도지명 리스트 준비\n",
    "CB=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\충청북도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        CB.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "CB = CB[0].split(' ')\n",
    "CB.remove('')\n",
    "print(CB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['예산군', '부여군', '보령시', '청양군', '논산시', '당진시', '태안군', '계룡시', '공주시', '천안시', '서북구', '천안시', '동남구', '아산시', '금산군', '서천군', '서산시', '홍성군']\n"
     ]
    }
   ],
   "source": [
    "# 충청남도지명 리스트 준비\n",
    "CN=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\충청남도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        CN.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "CN = CN[0].split(' ')\n",
    "CN.remove('')\n",
    "print(CN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['제주시', '서귀포시']\n"
     ]
    }
   ],
   "source": [
    "# 제주특별자치도지명 리스트 준비\n",
    "JJ=[]\n",
    "file=open('C:\\\\Python\\\\source\\\\adress_db\\\\제주특별자치도list.txt','rt' , encoding='UTF-8')\n",
    "\n",
    "while (1):\n",
    "    line=file.readline()\n",
    "    try:escape=line.index('\\n')\n",
    "    except:escape=len(line)\n",
    "    if line:\n",
    "        JJ.append(line[0:escape])\n",
    "    else:\n",
    "        break\n",
    "file.close()\n",
    "\n",
    "JJ = JJ[0].split(' ')\n",
    "JJ.remove('')\n",
    "print(JJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               자유한국당 신보라 의원왼쪽과 황교안 대표. 동아일보       ...\n",
      "1               지난 29일 경북 영양에 있는 국립생태원 멸종위기종복원센터에서 ...\n",
      "2               무소속 이언주 국회의원이 2일 충북 청주시 상당공원 인근 도로에...\n",
      "3               여기 저기 티켓다방 천안연합뉴스 이은중 기자  충남 천안시 성환...\n",
      "4               지난달 31일 청주시 서원구 사직동 충혼탑 입구에 설치된 천지신...\n",
      "5               김정은          지난 3월 “남북 접촉을 중단하라”고 지...\n",
      "6    【서울뉴시스】옥성구 기자  역무원을 향해 너 직급이 뭐야라며 소리치고 공사 직원에게...\n",
      "7               수사본부인 경기남부경찰청은 2일 오전 9시부터 경기 화성시 소재...\n",
      "8    앵커여러분 안녕하십니까 토요일밤 9시뉴스입니다.소방헬기가 추락한 독도 인근 해역에서...\n",
      "9    엄마 걱정 마. 소방관 일 생각보다 안전해. 생명을 구하러 달려가는 거잖아.소방관이...\n",
      "Name: article, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 2. article 컬럼만 추출(원본), sentence(특수문자, stop word 적용)\n",
    "article_list = csv_data.article\n",
    "print(article_list[:10])\n",
    "#article_list[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특수문자 제거 sentence[1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3_1. 특수문자 제거\n",
    "\n",
    "# 소문자 변환\n",
    "# re 라이브러리로 특수문자 제거\n",
    "\n",
    "# 읽어온 데이터 확인 (json_body)\n",
    "\n",
    "sentence = []\n",
    "\n",
    "# 특수문자 제거 라이브러리\n",
    "import re\n",
    "for a in range(len(article_list)):\n",
    "    sentence.append(article_list[a].strip())\n",
    "    \n",
    "for i in range(len(sentence)):\n",
    "    sentence[i] = sentence[i].lower() # lower() : 모든 문자를 소문자로 변환\n",
    "    sentence[i] = re.sub(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\", ' ', sentence[i]) # 특수문자 제거\n",
    "    sentence[i] = re.sub(\"[.;:!\\'?,\\\"()|[\\]]\", ' ', sentence[i]) # 특수문자 제거\n",
    "\n",
    "print(\"특수문자 제거 sentence[1]\") # 모든 article을 sentence에 저장 후 특수문자 제거 및 (영어)소문자화 \n",
    "#print(sentence[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3_2. 외부 Stop Word 리스트 불러오기 (stop word ranking 기반) \n",
    "# 불용어 처리 - stop_word 리스트 불러오기 & 전처리\n",
    "stop_words = []\n",
    "f = open(\"C:\\Python\\source\\stop_word.txt\", 'r', encoding='UTF-8')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    #print(line) #정상 출력 확인\n",
    "    stop_words.append(line.rstrip('\\n')) # 개행문자 제거 후 추가\n",
    "f.close()\n",
    "\n",
    "# 불러온 stop word 리스트 출력\n",
    "#print(stop_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word 필터링 결과 (result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3_3. 불러온 Stop Word 적용  \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "result = [] \n",
    "for w in sentence: \n",
    "    if w not in stop_words: \n",
    "        result.append(w) \n",
    "\n",
    "# 위의 4줄은 아래의 한 줄로 대체 가능\n",
    "# result=[word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "# 불용어 처리 결과 출력\n",
    "print(\"stop word 필터링 결과 (result)\")\n",
    "#print(result[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아프리카 포함 인덱스 [1, 35, 96, 103, 168, 394, 442, 569]\n",
      "돼지 포함 인덱스 [35, 96, 137, 168, 202, 406, 428, 442, 457, 569]\n",
      "야생 포함 인덱스 [1, 96, 145, 168, 439, 474, 501, 532, 569]\n",
      "방역 포함 인덱스 [476, 688]\n",
      "멧돼지 포함 인덱스 [96, 137, 168, 406, 569]\n",
      "아프리카 + 돼지 인덱스 :  [96, 35, 168, 569, 442]\n"
     ]
    }
   ],
   "source": [
    "# 연산 절약을 위해 키워드를 통한 필터링\n",
    "keyw = ['아프리카', '돼지', '야생', '방역', '멧돼지', '발생']\n",
    "w_list0 = []\n",
    "w_list1 = []\n",
    "w_list2 = []\n",
    "w_list3 = []\n",
    "w_list4 = []\n",
    "w_list5 = []\n",
    "w_list6 = []\n",
    "w_list7 = []\n",
    "w_list8 = []\n",
    "\n",
    "# 아프리카\n",
    "for i in range(len(sentence)):\n",
    "    if( sentence[i].find(keyw[0]) >= 0 ):\n",
    "        w_list0.append(i)\n",
    "# 돼지\n",
    "for i in range(len(sentence)):\n",
    "    if( sentence[i].find(keyw[1]) >= 0 ):\n",
    "        w_list1.append(i)\n",
    "# 야생\n",
    "for i in range(len(sentence)):\n",
    "    if( sentence[i].find(keyw[2]) >= 0 ):\n",
    "        w_list2.append(i)\n",
    "# 방역\n",
    "for i in range(len(sentence)):\n",
    "    if( sentence[i].find(keyw[3]) >= 0 ):\n",
    "        w_list3.append(i)\n",
    "# 멧돼지  \n",
    "for i in range(len(sentence)):\n",
    "    if( sentence[i].find(keyw[4]) >= 0 ):\n",
    "        w_list4.append(i)\n",
    "# 발생\n",
    "for i in range(len(sentence)):\n",
    "    if( sentence[i].find(keyw[5]) >= 0 ):\n",
    "        w_list5.append(i)\n",
    "\n",
    "print(\"아프리카 포함 인덱스\",w_list0)\n",
    "print(\"돼지 포함 인덱스\",w_list1)\n",
    "print(\"야생 포함 인덱스\",w_list2)\n",
    "print(\"방역 포함 인덱스\",w_list3)\n",
    "print(\"멧돼지 포함 인덱스\",w_list4)\n",
    "\n",
    "# 살처분, 확진, 보상, 신고, 야생\n",
    "# 키워드 추출 리스트에서 중첩 인덱스 찾기\n",
    "\n",
    "# 아프리카 + 돼지\n",
    "u_list = list(set(w_list0).intersection(w_list1))\n",
    "print(\"아프리카 + 돼지 인덱스 : \", u_list)\n",
    "\n",
    "# (아프리카 + 돼지) + 야생\n",
    "#u_list = list(set(u_list).intersection(w_list2))\n",
    "#print(\"아프리카 + 돼지 + 야생 인덱스 : \", u_list)\n",
    "\n",
    "# (돼지 + 방역 + 야생) + \n",
    "\n",
    "#비교대상 1251, 295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_article = []    # 선별한 인덱스의 article만 뽑아서 f_article = mydoclist 에 저장\n",
    "for numm in u_list:\n",
    "    f_article.append(sentence[numm])\n",
    "    #print(sentence[numm])\n",
    "    #print()\n",
    "    \n",
    "# 추출한 명사를 리스트로 만들기\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from konlpy.tag import Kkma, Twitter, Hannanum, Komoran\n",
    "from konlpy.utils import pprint\n",
    "\n",
    "mydoclist = f_article\n",
    "\n",
    "# twitter 와 komoran이 가장 높은 유사도를 보인다.\n",
    "#kkma = Kkma()\n",
    "#twitt = Twitter()\n",
    "#hann = Hannanum()\n",
    "komo = Komoran()\n",
    "\n",
    "doc_nouns_list = [] \n",
    " \n",
    "for doc in mydoclist:\n",
    "    nouns = komo.nouns(doc)\n",
    "    doc_nouns = ''\n",
    " \n",
    "    for noun in nouns:\n",
    "        doc_nouns += noun + ' ' # 추출한 명사를 문장으로 합침\n",
    " \n",
    "    doc_nouns_list.append(doc_nouns) # doc_nouns_list에 추가\n",
    " \n",
    "#print(doc_nouns_list[1])\n",
    "#for arti in doc_nouns_list:\n",
    "#    print(arti)\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#참조 : https://bab2min.tistory.com/570\n",
    "#!pip install networkx\n",
    "import networkx\n",
    "import re\n",
    "\n",
    "class RawSentence:\n",
    "    def __init__(self, textIter):\n",
    "        if type(textIter) == str: self.textIter = textIter.split('\\n')\n",
    "        else: self.textIter = textIter\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in self.textIter:\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield s\n",
    " \n",
    "class RawSentenceReader:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield s\n",
    " \n",
    "class RawTagger:\n",
    "    def __init__(self, textIter, tagger = None):\n",
    "        if tagger:\n",
    "            self.tagger = tagger\n",
    "        else :\n",
    "            from konlpy.tag import Komoran\n",
    "            self.tagger = Komoran()\n",
    "        if type(textIter) == str: self.textIter = textIter.split('\\n')\n",
    "        else: self.textIter = textIter\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in self.textIter:\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            if len(ch) == 1:\n",
    "                ch.append(\".\")\n",
    "                \n",
    "            for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield self.tagger.pos(s)\n",
    " \n",
    "class RawTaggerReader:\n",
    "    def __init__(self, filepath, tagger = None):\n",
    "        if tagger:\n",
    "            self.tagger = tagger\n",
    "        else :\n",
    "            from konlpy.tag import Komoran\n",
    "            self.tagger = Komoran()\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
    "                if not s: continue\n",
    "                yield self.tagger.pos(s)\n",
    " \n",
    "class TextRank:\n",
    "    def __init__(self, **kargs):\n",
    "        self.graph = None\n",
    "        self.window = kargs.get('window', 5)\n",
    "        self.coef = kargs.get('coef', 1.0)\n",
    "        self.threshold = kargs.get('threshold', 0.005)\n",
    "        self.dictCount = {}\n",
    "        self.dictBiCount = {}\n",
    "        self.dictNear = {}\n",
    "        self.nTotal = 0\n",
    " \n",
    " \n",
    "    def load(self, sentenceIter, wordFilter = None):\n",
    "        def insertPair(a, b):\n",
    "            if a > b: a, b = b, a\n",
    "            elif a == b: return\n",
    "            self.dictBiCount[a, b] = self.dictBiCount.get((a, b), 0) + 1\n",
    " \n",
    "        def insertNearPair(a, b):\n",
    "            self.dictNear[a, b] = self.dictNear.get((a, b), 0) + 1\n",
    " \n",
    "        for sent in sentenceIter:\n",
    "            for i, word in enumerate(sent):\n",
    "                if wordFilter and not wordFilter(word): continue\n",
    "                self.dictCount[word] = self.dictCount.get(word, 0) + 1\n",
    "                self.nTotal += 1\n",
    "                if i - 1 >= 0 and (not wordFilter or wordFilter(sent[i-1])): insertNearPair(sent[i-1], word)\n",
    "                if i + 1 < len(sent) and (not wordFilter or wordFilter(sent[i+1])): insertNearPair(word, sent[i+1])\n",
    "                for j in range(i+1, min(i+self.window+1, len(sent))):\n",
    "                    if wordFilter and not wordFilter(sent[j]): continue\n",
    "                    if sent[j] != word: insertPair(word, sent[j])\n",
    " \n",
    "    def loadSents(self, sentenceIter, tokenizer = None):\n",
    "        import math\n",
    "        def similarity(a, b):\n",
    "            n = len(a.intersection(b))\n",
    "            return n / float(len(a) + len(b) - n) / (math.log(len(a)+1) * math.log(len(b)+1))\n",
    " \n",
    "        if not tokenizer: rgxSplitter = re.compile('[\\\\s.,:;-?!()\"\\']+')\n",
    "        sentSet = []\n",
    "        for sent in filter(None, sentenceIter):\n",
    "            if type(sent) == str:\n",
    "                if tokenizer: s = set(filter(None, tokenizer(sent)))\n",
    "                else: s = set(filter(None, rgxSplitter.split(sent)))\n",
    "            else: s = set(sent)\n",
    "            if len(s) < 2: continue\n",
    "            self.dictCount[len(self.dictCount)] = sent\n",
    "            sentSet.append(s)\n",
    " \n",
    "        for i in range(len(self.dictCount)):\n",
    "            for j in range(i+1, len(self.dictCount)):\n",
    "                s = similarity(sentSet[i], sentSet[j])\n",
    "                if s < self.threshold: continue\n",
    "                self.dictBiCount[i, j] = s\n",
    " \n",
    "    def getPMI(self, a, b):\n",
    "        import math\n",
    "        co = self.dictNear.get((a, b), 0)\n",
    "        if not co: return None\n",
    "        return math.log(float(co) * self.nTotal / self.dictCount[a] / self.dictCount[b])\n",
    " \n",
    "    def getI(self, a):\n",
    "        import math\n",
    "        if a not in self.dictCount: return None\n",
    "        return math.log(self.nTotal / self.dictCount[a])\n",
    " \n",
    "    def build(self):\n",
    "        self.graph = networkx.Graph()\n",
    "        self.graph.add_nodes_from(self.dictCount.keys())\n",
    "        for (a, b), n in self.dictBiCount.items():\n",
    "            self.graph.add_edge(a, b, weight=n*self.coef + (1-self.coef))\n",
    " \n",
    "    def rank(self):\n",
    "        return networkx.pagerank(self.graph, weight='weight')\n",
    " \n",
    "    def extract(self, ratio = 0.1):\n",
    "        ranks = self.rank()\n",
    "        cand = sorted(ranks, key=ranks.get, reverse=True)[:int(len(ranks) * ratio)]\n",
    "        pairness = {}\n",
    "        startOf = {}\n",
    "        tuples = {}\n",
    "        for k in cand:\n",
    "            tuples[(k,)] = self.getI(k) * ranks[k]\n",
    "            for l in cand:\n",
    "                if k == l: continue\n",
    "                pmi = self.getPMI(k, l)\n",
    "                if pmi: pairness[k, l] = pmi\n",
    " \n",
    "        for (k, l) in sorted(pairness, key=pairness.get, reverse=True):\n",
    "            print(k[0], l[0], pairness[k, l])\n",
    "            if k not in startOf: startOf[k] = (k, l)\n",
    " \n",
    "        for (k, l), v in pairness.items():\n",
    "            pmis = v\n",
    "            rs = ranks[k] * ranks[l]\n",
    "            path = (k, l)\n",
    "            tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    "            last = l\n",
    "            while last in startOf and len(path) < 7:\n",
    "                if last in path: break\n",
    "                pmis += pairness[startOf[last]]\n",
    "                last = startOf[last][1]\n",
    "                rs *= ranks[last]\n",
    "                path += (last,)\n",
    "                tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    " \n",
    "        used = set()\n",
    "        both = {}\n",
    "        for k in sorted(tuples, key=tuples.get, reverse=True):\n",
    "            if used.intersection(set(k)): continue\n",
    "            both[k] = tuples[k]\n",
    "            for w in k: used.add(w)\n",
    " \n",
    "        #for k in cand:\n",
    "        #    if k not in used or True: both[k] = ranks[k] * self.getI(k)\n",
    " \n",
    "        return both\n",
    " \n",
    "        #0.333\n",
    "    def summarize(self, ratio = 0.333):\n",
    "        r = self.rank()\n",
    "        ks = sorted(r, key=r.get, reverse=True)[:int(len(r)*ratio)]\n",
    "        return ' '.join(map(lambda k:self.dictCount[k], sorted(ks)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntr = TextRank()\\nprint(\\'Load...\\')\\nfrom konlpy.tag import Komoran\\ntagger = Komoran()\\nstopword = set([(\\'있\\', \\'VV\\'), (\\'하\\', \\'VV\\'), (\\'되\\', \\'VV\\') ])\\n#tr.loadSents(doc_nouns_list[0], lambda sent: filter(lambda x:x not in stopword and x[1] in (\\'NNG\\', \\'NNP\\', \\'VV\\', \\'VA\\'), tagger.pos(sent)))\\ntr.loadSents(RawTagger(doc_nouns_list[1]), lambda sent: filter(lambda x:x not in stopword and x[1] in (\\'NNG\\', \\'NNP\\', \\'VV\\', \\'VA\\'), tagger.pos(sent)))\\n# RawTagger(\"특정 텍스트....\")\\n#tr = doc_nouns_list[0]\\nprint(\\'Build...\\')\\ntr.build()\\nranks = tr.rank()\\nfor k in sorted(ranks, key=ranks.get, reverse=True)[:100]:\\n    print(\"\\t\".join([str(k), str(ranks[k]), str(tr.dictCount[k])]))\\n    \\nprint(tr.summarize(0.1))\\n\\n'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tr = TextRank()\n",
    "print('Load...')\n",
    "from konlpy.tag import Komoran\n",
    "tagger = Komoran()\n",
    "stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV') ])\n",
    "#tr.loadSents(doc_nouns_list[0], lambda sent: filter(lambda x:x not in stopword and x[1] in ('NNG', 'NNP', 'VV', 'VA'), tagger.pos(sent)))\n",
    "tr.loadSents(RawTagger(doc_nouns_list[1]), lambda sent: filter(lambda x:x not in stopword and x[1] in ('NNG', 'NNP', 'VV', 'VA'), tagger.pos(sent)))\n",
    "# RawTagger(\"특정 텍스트....\")\n",
    "#tr = doc_nouns_list[0]\n",
    "print('Build...')\n",
    "tr.build()\n",
    "ranks = tr.rank()\n",
    "for k in sorted(ranks, key=ranks.get, reverse=True)[:100]:\n",
    "    print(\"\\t\".join([str(k), str(ranks[k]), str(tr.dictCount[k])]))\n",
    "    \n",
    "print(tr.summarize(0.1))\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load...\n",
      "Build...\n",
      "돼지 열병 5.1298987149230735\n",
      "손흥민 태클 4.318968498706745\n",
      "오늘 오후 4.318968498706745\n",
      "권혁수 오늘 4.0312864262549635\n",
      "권혁수 사실 4.0312864262549635\n",
      "사실 권혁수 4.0312864262549635\n",
      "부상 사고 4.0312864262549635\n",
      "경기장 사진 4.0312864262549635\n",
      "방송 권혁수 4.0312864262549635\n",
      "고메스 부상 3.8081428749407538\n",
      "부상 정국 3.6258213181467993\n",
      "고메스 토트넘 3.520460802488973\n",
      "사고 고메스 3.520460802488973\n",
      "손흥민 토트넘 3.3381392456950185\n",
      "정국 사진 3.3381392456950185\n",
      "사고 손흥민 3.3381392456950185\n",
      "토트넘 손흥민 3.3381392456950185\n",
      "손흥민\n",
      "태클\n",
      "topkey :  손흥민태클\n",
      "돼지\n",
      "열병\n",
      "topkey :  손흥민태클돼지열병\n",
      "권혁수\n",
      "오늘\n",
      "topkey :  손흥민태클돼지열병권혁수오늘\n",
      "사고\n",
      "고메스\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스\n",
      "부상\n",
      "정국\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국\n",
      "경기장\n",
      "사진\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진\n",
      "홍\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍\n",
      "상\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상\n",
      "토트넘\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘\n",
      "멧돼지\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지\n",
      "사실\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실\n",
      "진행\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행\n",
      "재판\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행재판\n",
      "오후\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행재판오후\n",
      "팬\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행재판오후팬\n",
      "방송\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행재판오후팬방송\n",
      "현장\n",
      "topkey :  손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행재판오후팬방송현장\n",
      "\n",
      "Load...\n",
      "Build...\n",
      "내국인 채용 4.326337728813293\n",
      "고용 허가 4.103194177499083\n",
      "캄보디아 외국인 노동자 3.9208726207051288\n",
      "캄보디아 끼 3.9208726207051288\n",
      "끼 캄보디아 3.9208726207051288\n",
      "노동자 불법체류 3.6331905482533475\n",
      "동의 불법체류 3.6331905482533475\n",
      "채용 외국인 2.822260332037019\n",
      "내국인 외국인 2.534578259585238\n",
      "외국인 허가 2.3114347082710283\n",
      "외국인 고용 2.1291131514770734\n",
      "외국인 외국인 노동자 2.1291131514770734\n",
      "고용\n",
      "허가\n",
      "topkey :  고용허가\n",
      "내국인\n",
      "채용\n",
      "topkey :  고용허가내국인채용\n",
      "캄보디아\n",
      "외국인 노동자\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자\n",
      "외국인\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인\n",
      "노동자\n",
      "불법체류\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류\n",
      "생산\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류생산\n",
      "소정\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류생산소정\n",
      "사람\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류생산소정사람\n",
      "겁\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류생산소정사람겁\n",
      "끼\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류생산소정사람겁끼\n",
      "동의\n",
      "topkey :  고용허가내국인채용캄보디아외국인 노동자외국인노동자불법체류생산소정사람겁끼동의\n",
      "\n",
      "Load...\n",
      "Build...\n",
      "아프리카 돼지 4.074141854904581\n",
      "돼지 열병 4.074141854904581\n",
      "포획 틀 3.7376696182833684\n",
      "틀 멧돼지 3.1986731175506815\n",
      "멧돼지 아프리카 2.570064458128307\n",
      "아프리카\n",
      "돼지\n",
      "topkey :  아프리카돼지\n",
      "포획\n",
      "틀\n",
      "topkey :  아프리카돼지포획틀\n",
      "멧돼지\n",
      "topkey :  아프리카돼지포획틀멧돼지\n",
      "열병\n",
      "topkey :  아프리카돼지포획틀멧돼지열병\n",
      "철원군\n",
      "topkey :  아프리카돼지포획틀멧돼지열병철원군\n",
      "민통선\n",
      "topkey :  아프리카돼지포획틀멧돼지열병철원군민통선\n",
      "\n",
      "Load...\n",
      "Build...\n",
      "엽 사 4.637960008811082\n",
      "민간 엽 4.3866455805301765\n",
      "대응 전담 4.196127256532043\n",
      "신고 대응 4.196127256532043\n",
      "땅 흔적 4.127134385045092\n",
      "전담 경찰관 4.0783442208756595\n",
      "사냥 팀 3.770459441106359\n",
      "소속 민간 3.721669276936927\n",
      "전담 대응 3.502980075972098\n",
      "엽총 권총 3.369448683347575\n",
      "흔적 경찰 3.2516656476911914\n",
      "엽총 훈련 3.1463051320333655\n",
      "멧돼지 신고 3.0329764467263622\n",
      "소속 경찰관 3.028522096376982\n",
      "소속 엽 3.028522096376982\n",
      "경찰관 팀 3.0285220963769817\n",
      "팀 소속 2.9231615807191558\n",
      "신고 민간 2.692049859755769\n",
      "강릉경찰서 멧돼지 2.67630150278763\n",
      "엽총 경찰관 2.5585184671312464\n",
      "경찰 사냥 2.3353749158170367\n",
      "강릉경찰서 사냥 2.3353749158170367\n",
      "멧돼지 흔적 2.270836394679465\n",
      "팀 출동 2.2300144001592104\n",
      "팀 땅 2.2300144001592104\n",
      "전담 사냥 2.181224235989778\n",
      "사 멧돼지 2.116685714852207\n",
      "팀 경찰 2.0476928433652555\n",
      "멧돼지 권총 1.9831543222276844\n",
      "경찰관 사냥 1.929909807708872\n",
      "멧돼지 땅 1.7600107709134747\n",
      "출동 멧돼지 1.7600107709134747\n",
      "팀 민간 1.6422277352570913\n",
      "멧돼지 경찰 1.57768921411952\n",
      "팀 멧돼지 1.4723286984616937\n",
      "멧돼지 전담 1.4235385342922617\n",
      "멧돼지 사냥 1.3545456628053103\n",
      "팀 경위 1.274502955131774\n",
      "멧돼지 민간 1.1722241060113556\n",
      "경찰관 멧돼지 1.1722241060113556\n",
      "멧돼지 경위 0.8044993258860382\n",
      "경위 멧돼지 0.8044993258860382\n",
      "사냥\n",
      "팀\n",
      "topkey :  사냥팀\n",
      "멧돼지\n",
      "신고\n",
      "topkey :  사냥팀멧돼지신고\n",
      "민간\n",
      "엽\n",
      "topkey :  사냥팀멧돼지신고민간엽\n",
      "전담\n",
      "경찰관\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관\n",
      "땅\n",
      "흔적\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적\n",
      "엽총\n",
      "권총\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총\n",
      "경위\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위\n",
      "대응\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응\n",
      "경찰\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰\n",
      "강릉경찰서\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰강릉경찰서\n",
      "사\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰강릉경찰서사\n",
      "출동\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰강릉경찰서사출동\n",
      "소속\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰강릉경찰서사출동소속\n",
      "훈련\n",
      "topkey :  사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰강릉경찰서사출동소속훈련\n",
      "\n",
      "Load...\n",
      "Build...\n",
      "노동부 장관 4.8283137373023015\n",
      "고용 부 4.509860006183767\n",
      "인가 요건 4.509860006183767\n",
      "고용 노동부 4.509860006183766\n",
      "요건 확대 4.422848629194137\n",
      "노동부 시행 3.912023005428146\n",
      "확대 시행 3.912023005428146\n",
      "장관 인가 3.816712825623821\n",
      "국회 입법 3.7297014486341915\n",
      "부 장관 3.7297014486341915\n",
      "확대 뉴스1 3.7297014486341915\n",
      "경우 기업 3.7297014486341915\n",
      "연장 근로 3.4420193761824107\n",
      "탄력 근로 3.4420193761824107\n",
      "노동 기업 3.324236340526027\n",
      "부 계 3.324236340526027\n",
      "장관 탄력 3.324236340526027\n",
      "경우 탄력 3.324236340526027\n",
      "근로 인가 3.241348680720259\n",
      "기간 확대 3.2188758248682006\n",
      "시간 대응 3.1010927892118176\n",
      "인가 업무 2.900422093749666\n",
      "확대 시간 2.8134107167600364\n",
      "확대 연장 2.5770219386958058\n",
      "시간 계 2.4079456086518722\n",
      "국회 연장 2.1715568305876416\n",
      "기자 연장 2.1715568305876416\n",
      "대응 연장 2.1715568305876416\n",
      "기업 연장 2.1715568305876416\n",
      "근로 시간 1.8325814637483102\n",
      "근로 고용 1.7372712839439852\n",
      "근로 대응 1.6502599069543555\n",
      "기업 근로 1.6502599069543555\n",
      "시간 연장 1.2552660987134865\n",
      "근로 탄력 1.2447947988461912\n",
      "근로 기간 1.1394342831883648\n",
      "연장\n",
      "근로\n",
      "topkey :  연장근로\n",
      "고용\n",
      "부\n",
      "topkey :  연장근로고용부\n",
      "인가\n",
      "요건\n",
      "topkey :  연장근로고용부인가요건\n",
      "시간\n",
      "대응\n",
      "topkey :  연장근로고용부인가요건시간대응\n",
      "노동부\n",
      "장관\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관\n",
      "기간\n",
      "확대\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대\n",
      "노동\n",
      "기업\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업\n",
      "경우\n",
      "탄력\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력\n",
      "국회\n",
      "입법\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법\n",
      "계\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법계\n",
      "기자\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법계기자\n",
      "시행\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법계기자시행\n",
      "뉴스1\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법계기자시행뉴스1\n",
      "간사\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법계기자시행뉴스1간사\n",
      "업무\n",
      "topkey :  연장근로고용부인가요건시간대응노동부장관기간확대노동기업경우탄력국회입법계기자시행뉴스1간사업무\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_key_list = []\n",
    "\n",
    "for arti in doc_nouns_list:\n",
    "    tr = TextRank(window=5, coef=1)\n",
    "    print('Load...')\n",
    "    stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV'), ('없', 'VV') ])\n",
    "    tr.load(RawTagger(arti), lambda w: w not in stopword and (w[1] in ('NNG', 'NNP', 'VV', 'VA')))\n",
    "    print('Build...')\n",
    "    tr.build()\n",
    "    kw = tr.extract(0.1)\n",
    "    top_key = []\n",
    "    for k in sorted(kw, key=kw.get, reverse=True):\n",
    "        \n",
    "        #print(\"%s\\t%g\" % (k, kw[k]))\n",
    "        for kk in k:\n",
    "            print(kk[0])\n",
    "            top_key += kk[0]\n",
    "            #top_key += list(k[kk])\n",
    "        top_key = ''.join(top_key)\n",
    "        print(\"topkey : \", top_key)\n",
    "    top_key_list.append(top_key)\n",
    "    \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "\n",
      "사냥팀멧돼지신고민간엽전담경찰관땅흔적엽총권총경위대응경찰강릉경찰서사출동소속훈련\n",
      "기사 번호:  0\n",
      "손흥민태클돼지열병권혁수오늘사고고메스부상정국경기장사진홍상토트넘멧돼지사실진행재판오후팬방송현장  지명 추출 :  경기\n",
      "['경기']\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#print(''.join(top_key))\n",
    "print(top_key.find(\"하하\"))\n",
    "#if (top_key.find(\"text\") != -1)\n",
    "#print(top_key[1])\n",
    "print()\n",
    "print(top_key_list[3])\n",
    "local_name = []\n",
    "local_list = [\"경기\", \"강원\", \"광주\", \"경북\", \"경남\", \"대구\", \"대전\", \"부산\", \"서울\", \"세종\", \"울산\", \"인천\", \"전남\", \"전북\", \"제주\", \"충남\", \"충북\" ]\n",
    "local_result = []\n",
    "# 지명 찾기\n",
    "article_count = 0\n",
    "art_count_list = []\n",
    "for i in top_key_list:\n",
    "    \n",
    "    for j in local_list:\n",
    "        #print(j)\n",
    "        local_num = i.find(j) # 지명 스캔   #이제 원본 기사 불러와서 지명 찾기\n",
    "        if local_num != -1 :\n",
    "            print(\"기사 번호: \", article_count)\n",
    "            art_count_list.append(article_count)\n",
    "            print(i, \" 지명 추출 : \", j)\n",
    "            if j == '강원':\n",
    "                print (\"강원도 도시 비교\")\n",
    "            if j == '경기':\n",
    "                for jj in GGD:\n",
    "                    l_num = i.find(jj)\n",
    "                    \n",
    "                    if l_num != -1:\n",
    "                        print(\"도시 발견! : \", jj)\n",
    "                        local_name.append(jj)\n",
    "                    \n",
    "            \n",
    "                \n",
    "            #print(j)\n",
    "            local_result.append(j)\n",
    "            \n",
    "    article_count +=1\n",
    "            \n",
    "print(local_result)\n",
    "print(art_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96, 35, 168, 569, 442]\n",
      "\n",
      "[0]\n",
      "article index :  96\n",
      " 이데일리 박한나 기자 이데일리가 오늘 하루의 주요 이슈를 모아 퇴근길 뉴스로 독자들을 찾아갑니다. 정치 경제 사회 문화 스포츠 등 퇴근길에 가볍게 읽을 수 있는 세상 소식을 매일 오후 5시에 배달합니다. 편집자주          ■          방탄소년단 정국 교통사고에 팬들 ‘깜짝’           방탄소년단 정국사진 뉴시스                    그룹 방탄소년단 정국본명 전정국의 교통사고 소식이 전해져서 깜짝 놀란 팬들이 많을텐데요. 정국은 지난 2일 용산구 한남동 한 거리에서 자신의 벤츠 차량을 몰다가 도로교통법규를 위반해 운행하던 중 지나가던 택시와 부딪혔다고 합니다. 정국과 택시 차량 운전자 모두 타박상을 입어 병원에서 치료를 받았습니다. 이와 관련 빅히트 엔터테인먼트가 오늘 오후 발표한 입장에 따르면 두 사람 모두 큰 부상은 없다고 합니다.          또 정국 본인의 착오로 접촉사고가 발생했으나 음주운전은 아니라고 밝혔습니다. 빅히트 측은 “정국은 사고 직후 본인이 도로교통법을 위반했음을 인정하고 적법한 절차에 따라 현장 처리 및 경찰서 진술을 진행했으며 이후 피해자와 원만하게 합의를 완료했다”며 “피해자분께 다시 한번 사과드리며 팬 여러분께 심려를 끼쳐드린 점에 대해서도 사과의 말씀을 드린다”고 밝혔습니다.          ■구도쉘리 “상의 탈의 제안”  권혁수 “사실 아냐”유튜브 크리에이터 구도 쉘리와 방송인 권혁수가 지난 9월 국내 한 식당에서 공동 라이브 방송을 하던 중 구도쉘리가 상의를 벗고 브라톱만 입은 채 방송을 이어간 것을 두고 진실공방을 벌였습니다. 어제 구도쉘리가 논란의 상의 탈의 장면은 사실 권혁수가 제안해서 한 것인데 돌발행동을 한 것처럼 알려졌다고 주장했기 때문입니다. 이에 권혁수는 오늘 긴급 기자회견을 열고 “구도쉘리를 지켜주고 싶어서 그동안 함구하고 있었다”면서 “구도쉘리가 ‘오빠가 상의 탈의를 연출한 것처럼 해달라’라고 요청했지만 거짓말을 할 수는 없었다”고 반박했습니다. 이에 대해 구도쉘리는 아직까지 추가 입장을 밝히지 않았습니다.          ■           손흥민 태클 후 안드레 고메스 부상에 고개 숙여            잉글랜드 프리미어리그 토트넘의 손흥민이 백태클로 퇴장을 당한 뒤 두 손으로 얼굴을 감싸고 경기장을 빠져나오고 있다. 사진                    4일한국시간 토트넘과 에버턴의 경기 중 손흥민토트넘이 안드레 고메스의 공을 뺏기 위해 태클을 시도했습니다. 그러다 걸려 넘어진 고메스가 토트넘 세르주 오리에와 부딪혀 발목이 꺾이는 큰 부상사고가 있었습니다. 고메스는 들것에 실려 경기장 밖으로 나갔고 손흥민 역시 퇴장 명령을 받아 경기장 밖으로 갔습니다. 예상치 못한 사고로 손흥민 역시 큰 충격을 받아 라커룸에서도 불안정한 상태를 보였다고 합니다. 이에 상대 팀인 에버튼 주장과 선수들도 고메스의 쾌유를 비는 동시에 손흥민이 고의로 한 행동이 아님을 믿는다며 그를 위로했습니다.          ■           아프리카돼지열병 불안 아직...로드킬 ‘맷돼지’도 검사           지난달 16일 오후 충북 청주시 상당구 탑동 한 도로에서 멧돼지 한 마리가 1 화물차에 치어 죽어 있는 모습. 사진은 기사 내용과 직접적 관련 없음 사진뉴시스                    아프리카돼지열병의 불안이 계속되고 있습니다. 서울 은평구 한 도로에서 차에 치여 죽은 채로 발견된 멧돼지 1마리를 대상으로 돼지열병 감염여부 조사가 진행 중입니다. 은평소방서는 4일 오전 3시 50분쯤 ‘출근길에 차로 멧돼지를 치었다’는 신고를 받은 뒤 현장에 출동해 멧돼지 사체를 확인했다고 밝혔습니다. 소방당국은 경찰과 구청 등 관계기관에 이 사실을 통보했고 사체는 야생생물관리협회 관계자가 인도받아 매장했다. 협회 관계자는 “ 감염 여부 등을 확인하기 위해 혈액을 채취해 서울시 보건환경연구소에 전달했다”고 전했습니다.          ■           마약 혐의로 기소된 홍정욱 전 의원 딸 측 “재판 빨리”          대마 흡입·밀반입 혐의로 적발된 홍정욱 전 한나라당자유한국당 전신 의원의 장녀 홍모양18의 재판이 12일로 예정됐는데요. 홍양 측은 공판준비기일에 공판준비기일을 빨리 지정해달라는 뜻을 밝혔다고 합니다. 홍양 측은 최근 ‘절차 진행에 관한 의견서’를 제출했습니다. 홍양 측 변호인은 재판부에 ‘홍양이 매우 힘들어하고 있어 재판을 빨리 받고 싶다’는 의견을 전달한 것으로 알려졌습니다.          박한나 ..          \n",
      "\n",
      "경기\n",
      "서울\n",
      "충북\n"
     ]
    }
   ],
   "source": [
    "print(u_list)\n",
    "print()\n",
    "print(art_count_list)\n",
    "\n",
    "locale_list = [] # 원문 기사를 찾기 위한 반복변수\n",
    "result_loc = [] # 추출한 지명 저장 변수\n",
    "\n",
    "# 다시 일치하는 기사의 원문 가져오기\n",
    "for num in art_count_list:\n",
    "    print(\"article index : \", u_list[num])\n",
    "    print(article_list[u_list[num]])\n",
    "    print()\n",
    "    \n",
    "    # 여기서 지명 추출\n",
    "    for i in local_list:\n",
    "        numl = article_list[u_list[num]].find(i)\n",
    "        if numl != -1:\n",
    "            print(i)\n",
    "            # case 강원도\n",
    "            if i == '강원':\n",
    "                for loc in KW:\n",
    "\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('강원도')\n",
    "                        result_loc.append(loc)\n",
    "            \n",
    "            # case 경기도\n",
    "            if i == '경기':         \n",
    "                for loc in GGD:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        print(idate = int(filter(str.isdigit,'기사내용')))\n",
    "                        result_loc.append('경기도')\n",
    "                        result_loc.append(loc)\n",
    "        \n",
    "# local_list = [\"경기\", \"강원\", \"광주\", \"경북\", \"경남\", \"대구\", \"대전\", \"부산\", \"서울\", \"세종\", \"울산\", \"인천\", \"전남\", \"전북\", \"제주\", \"충남\", \"충북\" ]\n",
    "\n",
    "            # case 경상남도 GSND\n",
    "            if i == '경남':\n",
    "                \n",
    "                for loc in GSND:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('경상남도')\n",
    "                        result_loc.append(loc)\n",
    "            \n",
    "            # case 경상북도 GSBD\n",
    "            if i == '경북':\n",
    "                \n",
    "                for loc in GSBD:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('경상북도')\n",
    "                        result_loc.append(loc)\n",
    "            \n",
    "            # case 광주 GJ\n",
    "            if i == '광주':\n",
    "                for loc in GJ:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('광주광역시')\n",
    "                        result_loc.append(loc)\n",
    "            \n",
    "            # case 대구 JG\n",
    "            if i == '대구':\n",
    "                for loc in DG:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('대구광역시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 대전 DJ\n",
    "            if i == '대전':\n",
    "                for loc in DJ:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('대전광역시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 부산 BS\n",
    "            if i == '부산':\n",
    "                for loc in BS:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('부산광역시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 서울 SO\n",
    "            if i == '서울':\n",
    "                for loc in SO:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('서울특별시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 세종 SJ\n",
    "            if i == '세종':\n",
    "                for loc in SJ:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('세종특별자치시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 울산 US\n",
    "            if i == '울산':\n",
    "                for loc in US:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('울산광역시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 인천 IC\n",
    "            if i == '인천':\n",
    "                for loc in IC:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('인천광역시')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 전북 JB\n",
    "            if i == '전북':\n",
    "                for loc in JB:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('전라북도')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 전남 JN\n",
    "            if i == '전남':\n",
    "                for loc in JN:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('전라남도')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 충북 CB\n",
    "            if i == '충북':\n",
    "                for loc in CB:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('충청북도')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 충남 CN\n",
    "            if i == '충남':\n",
    "                for loc in CN:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('충청남도')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            # case 제주 JJ\n",
    "            if i == '제주':\n",
    "                for loc in JJ:\n",
    "                    loc_num = article_list[u_list[num]].find(loc)\n",
    "                    if loc_num!= -1:\n",
    "                        result_loc.append('제주특별자치도')\n",
    "                        result_loc.append(loc)\n",
    "                        \n",
    "            \n",
    "            article_list[u_list[num]].find(i)\n",
    "            \n",
    "            \n",
    "    # 기사에서 날짜 추출\n",
    "          \n",
    "    #idate = int(filter(str.isdigit,'기사내용'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울특별시', '용산구', '서울특별시', '은평구', '충청북도', '청주시', '충청북도', '상당구', '충청북도', '청주시', '충청북도', '청주시', '충청북도', '청주시']\n"
     ]
    }
   ],
   "source": [
    "print(result_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울특별시 용산구', '서울특별시 은평구', '충청북도 청주시', '충청북도 상당구', '충청북도 청주시', '충청북도 청주시', '충청북도 청주시']\n"
     ]
    }
   ],
   "source": [
    "size = len(result_loc)/2\n",
    "\n",
    "print_out = []\n",
    "for_cnt = 0\n",
    "for i in range(0, int(size)):\n",
    "    print_out.append(result_loc[for_cnt] + ' ' + result_loc[for_cnt+1])\n",
    "    for_cnt +=2\n",
    "\n",
    "print(print_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
